{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up local directories where the results files are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_gams = \"/Users/lisarennels/JuliaProjects/CIAMPaper/local-data/gams-outputs/gams-results\"\n",
    "dir_julia = \"/Users/lisarennels/JuliaProjects/CIAMPaper/CIAM_adaptation_regimes/ciam-code/output/baseline_comparisons\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCP8.5 baseline results from Diaz 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_rcp85 = [\"rcp85p50ref\"+str(k)+\".csv\" for k in range(1,11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the files, place in a list of Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG_all = []\n",
    "for file in files_rcp85:\n",
    "    dfG_all.append(pd.read_csv(dir_gams+\"/rcp85/\"+file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenate all into a master file. don't worry about the times being out of order; the calculations will specify the year and type of damages to be summed up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG = pd.concat(dfG_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the list of DataFrames to save on some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfG_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix the segment names with apostrophes in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in dfG.segments.unique():\n",
    "    if '\\'' in seg:\n",
    "        new_name = seg.replace('\\'', '') \n",
    "        dfG.loc[(dfG.segments==seg), \"segments\"] = new_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather up Diaz 2016 results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoAdaptCost, OptimalCost, FloodNoAdapt, WetlandNoAdapt, RelocateNoAdapt, StormCapitalNoAdapt, StormPopNoAdapt, WetlandRetreat, WetlandProtect = [], [], [], [], [], [], [], [], []\n",
    "Construct10, ProtectCost10, StormPopProtect10, StormCapitalProtect10 = [], [], [], []\n",
    "Construct10000, ProtectCost10000, StormPopProtect10000, StormCapitalProtect10000 = [], [], [], []\n",
    "RetreatCost10, StormPopRetreat10, StormCapitalRetreat10, RelocateRetreat10 = [], [], [], []\n",
    "RetreatCost10000, StormPopRetreat10000, StormCapitalRetreat10000, RelocateRetreat10000 = [], [], [], []\n",
    "for t in range(1,11):\n",
    "    NoAdaptCost.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"NoAdaptCost\"), \"value\"].sum())\n",
    "    OptimalCost.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"OptimalFixedCost\"), \"value\"].sum())\n",
    "    FloodNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"FloodNoAdapt\"), \"value\"].sum())\n",
    "    WetlandNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"WetlandNoAdapt\"), \"value\"].sum())\n",
    "    RelocateNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"RelocateNoAdapt\"), \"value\"].sum())\n",
    "    StormCapitalNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"StormCapitalNoAdapt\"), \"value\"].sum())\n",
    "    StormPopNoAdapt.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"StormPopNoAdapt\"), \"value\"].sum())\n",
    "    WetlandRetreat.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"WetlandRetreat\"), \"value\"].sum())\n",
    "    WetlandProtect.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"variable\"]==\"WetlandProtect\"), \"value\"].sum())\n",
    "    Construct10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"ConstructOptimalFixed\"), \"value\"].sum())\n",
    "    ProtectCost10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"ProtectCost\"), \"value\"].sum())\n",
    "    StormPopProtect10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormPopProtect\"), \"value\"].sum())\n",
    "    StormCapitalProtect10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormCapitalProtect\"), \"value\"].sum())\n",
    "    RetreatCost10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"RetreatCost\"), \"value\"].sum())\n",
    "    StormPopRetreat10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormPopRetreat\"), \"value\"].sum())\n",
    "    StormCapitalRetreat10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"StormCapitalRetreat\"), \"value\"].sum())\n",
    "    RelocateRetreat10.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10) & (dfG[\"variable\"]==\"RelocateRetreat\"), \"value\"].sum())\n",
    "    Construct10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"ConstructOptimalFixed\"), \"value\"].sum())\n",
    "    ProtectCost10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"ProtectCost\"), \"value\"].sum())\n",
    "    StormPopProtect10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormPopProtect\"), \"value\"].sum())\n",
    "    StormCapitalProtect10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormCapitalProtect\"), \"value\"].sum())\n",
    "    RetreatCost10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"RetreatCost\"), \"value\"].sum())\n",
    "    StormPopRetreat10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormPopRetreat\"), \"value\"].sum())\n",
    "    StormCapitalRetreat10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"StormCapitalRetreat\"), \"value\"].sum())\n",
    "    RelocateRetreat10000.append(dfG.loc[(dfG[\"time\"]==t) & (dfG[\"level\"]==10000) & (dfG[\"variable\"]==\"RelocateRetreat\"), \"value\"].sum())\n",
    "\n",
    "dfDiaz = pd.DataFrame()\n",
    "dfDiaz[\"time\"] = list(range(2010,2110,10))\n",
    "dfDiaz[\"NoAdapt\"] = NoAdaptCost\n",
    "dfDiaz[\"Optimal\"] = OptimalCost\n",
    "dfDiaz[\"FloodNoAdapt\"] = FloodNoAdapt\n",
    "dfDiaz[\"WetlandNoAdapt\"] = WetlandNoAdapt\n",
    "dfDiaz[\"RelocateNoAdapt\"] = RelocateNoAdapt\n",
    "dfDiaz[\"StormCapitalNoAdapt\"] = StormCapitalNoAdapt\n",
    "dfDiaz[\"StormPopNoAdapt\"] = StormPopNoAdapt\n",
    "dfDiaz[\"WetlandProtect\"] = WetlandProtect\n",
    "#dfDiaz[\"Construct\"] = Construct\n",
    "dfDiaz[\"WetlandRetreat\"] = WetlandRetreat\n",
    "dfDiaz[\"ProtectCost10\"] = ProtectCost10\n",
    "dfDiaz[\"StormPopProtect10\"] = StormPopProtect10\n",
    "dfDiaz[\"StormCapitalProtect10\"] = StormCapitalProtect10\n",
    "dfDiaz[\"RetreatCost10\"] = RetreatCost10\n",
    "dfDiaz[\"StormPopRetreat10\"] = StormPopRetreat10\n",
    "dfDiaz[\"StormCapitalRetreat10\"] = StormCapitalRetreat10\n",
    "dfDiaz[\"RelocateRetreat10\"] = RelocateRetreat10\n",
    "dfDiaz[\"ProtectCost10000\"] = ProtectCost10000\n",
    "dfDiaz[\"StormPopProtect10000\"] = StormPopProtect10000\n",
    "dfDiaz[\"StormCapitalProtect10000\"] = StormCapitalProtect10000\n",
    "dfDiaz[\"RetreatCost10000\"] = RetreatCost10000\n",
    "dfDiaz[\"StormPopRetreat10000\"] = StormPopRetreat10000\n",
    "dfDiaz[\"StormCapitalRetreat10000\"] = StormCapitalRetreat10000\n",
    "dfDiaz[\"RelocateRetreat10000\"] = RelocateRetreat10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matches the paper well (Fig 2, right column), except in the last year when things jump up just a bit too much. Paper reports \\\\$2.2T in the NoAdapt case and \\\\$270B in the Optimal adaptation case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time  NoAdapt  Optimal\n",
      "0  2010   119.17    29.27\n",
      "1  2020   189.34    33.03\n",
      "2  2030   304.23    39.72\n",
      "3  2040   484.77    52.75\n",
      "4  2050   787.10   115.54\n",
      "5  2060  1217.03   132.09\n",
      "6  2070  1566.37   148.21\n",
      "7  2080  1878.13   163.73\n",
      "8  2090  2043.67   178.02\n",
      "9  2100  2251.46   282.07\n"
     ]
    }
   ],
   "source": [
    "print(np.round(dfDiaz[[\"time\",\"NoAdapt\",\"Optimal\"]],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC = pd.read_csv(dir_julia + \"/ctrl+noConstrFix_global_85p50ssp0fixed.csv\")\n",
    "dfN = pd.read_csv(dir_julia + \"/ctrl+noConstrFix_seg_85p50ssp0fixed.csv\")\n",
    "dfO = pd.read_csv(dir_julia + \"/ctrl+noConstrFix_seg_85p50ssp0fixed_optimal.csv\") # optimal actions for each segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or grab results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfC = pd.read_csv(\"dfC.csv\")\n",
    "# dfN = pd.read_csv(\"dfN.csv\")\n",
    "# dfO = pd.read_csv(\"dfO.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC1 = dfC.copy() # copies so that the new, shorter-foresight model version can be compared to old perfect foresight version\n",
    "dfN1 = dfN.copy()\n",
    "dfO1 = dfO.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPV foresight correction\n",
    "\n",
    "This correction accounts for the fact that the new version of CIAM considers NPV over the current adaptation period (40-50 years generally), whereas the previous GAMS version assumes NPV is known across the entire model time horizon (2000-2100, for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discount factor \n",
    "\n",
    "Matches output from a run model in Julia `m[:slrcost, :discountfactor]`\n",
    "\n",
    "`v.discountfactor[TimestepIndex(i)] = 1/(1 + p.discountrate)^(p.tstep * (i-1))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 6.75564169e-01 4.56386946e-01 3.08318668e-01\n",
      " 2.08289045e-01 1.40712615e-01 9.50604010e-02 6.42194008e-02\n",
      " 4.33843261e-02 2.93088962e-02 1.98000401e-02 1.33761976e-02\n",
      " 9.03647984e-03 6.10472199e-03 4.12413144e-03 2.78611543e-03\n",
      " 1.88219975e-03 1.27154671e-03 8.59011398e-04 5.80317321e-04]\n"
     ]
    }
   ],
   "source": [
    "drate = 0.04\n",
    "tstep = 10\n",
    "discountfactor = 1/(1+drate)**(tstep*np.arange(0,20,1))\n",
    "print(discountfactor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_G, segments_N = {}, {}\n",
    "for t in range(1,21):\n",
    "    segments_G[t] = list(dfG.loc[(dfG.time==t), \"segments\"].unique())\n",
    "    segments_N[t] = list(dfN.loc[(dfN.time==t), \"segments\"].unique())\n",
    "segments_G[\"all\"] = list(dfG.segments.unique())\n",
    "segments_N[\"all\"] = list(dfN.segments.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do the first time step separately. it is special because in the \"fixed\" mode a la original (GAMS) CIAM, this is where the adaptation strategy is determined. This strategy (including level) will be followed throughout the time horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol= 0.0001\n",
    "levs = {\"RetreatCost\" : [1,10,100,1000,10000], \"ProtectCost\" : [10,100,1000,10000], \"NoAdaptCost\" : [0]}\n",
    "options = []\n",
    "for var in [\"RetreatCost\",\"ProtectCost\"]:\n",
    "    for lev in levs[var]:\n",
    "            options.append(var+str(lev))\n",
    "options.append(\"NoAdaptCost0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find which segments have a mismatch; otherwise, this fix won't do anything since there's no change to the segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_G = {}\n",
    "dfGsub = dfG.loc[(dfG.time==1) & (dfG.variable.isin([\"OptimalFixedCost\",\"NoAdaptCost\",\"ProtectCost\",\"RetreatCost\"]))]\n",
    "for seg in dfGsub.loc[(dfGsub.time==1)&(dfGsub.variable==\"OptimalFixedCost\"), \"segments\"].unique():\n",
    "    cost = float(dfGsub.loc[(dfGsub.time==1) & (dfGsub.segments==seg) & (dfGsub.variable==\"OptimalFixedCost\"), \"value\"])\n",
    "    level_action = dfGsub.loc[(dfGsub.time==1) & (dfGsub.segments==seg) & \n",
    "                              (dfGsub.value==cost) & (dfGsub.variable!=\"OptimalFixedCost\"),[\"level\",\"variable\"]]\n",
    "    if level_action[\"variable\"].iloc[0]==\"NoAdaptCost\":\n",
    "        actions_G[seg] = level_action[\"variable\"].iloc[0]+\"0\"\n",
    "    else:\n",
    "        actions_G[seg] = level_action[\"variable\"].iloc[0]+str(int(level_action[\"level\"].iloc[0]))\n",
    "        \n",
    "actions_N = {}\n",
    "dfNsub = dfN.loc[(dfN.time==1) & (dfN.variable.isin([\"OptimalCost\",\"NoAdaptCost\",\"ProtectCost\",\"RetreatCost\"]))]\n",
    "for seg in dfNsub.loc[(dfNsub.time==1)&(dfNsub.variable==\"OptimalCost\"), \"segments\"].unique():\n",
    "    cost = float(dfNsub.loc[(dfNsub.time==1) & (dfNsub.segments==seg) & (dfNsub.variable==\"OptimalCost\"), \"value\"])\n",
    "    level_action = dfNsub.loc[(dfNsub.time==1) & (dfNsub.segments==seg) & \n",
    "                              (dfNsub.value==cost) & (dfNsub.variable!=\"OptimalCost\"),[\"level\",\"variable\"]]\n",
    "    if level_action[\"variable\"].iloc[0]==\"NoAdaptCost\":\n",
    "        actions_N[seg] = level_action[\"variable\"].iloc[0]+\"0\"\n",
    "    else:\n",
    "        actions_N[seg] = level_action[\"variable\"].iloc[0]+str(int(level_action[\"level\"].iloc[0]))\n",
    "        \n",
    "mismatches = {}\n",
    "for seg in actions_G.keys():\n",
    "    if actions_G[seg]!=actions_N[seg]:\n",
    "        mismatches[seg] = (actions_G[seg],actions_N[seg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the NPV using the full time horizon for decision-making (entire simulation period), instead of the new version's shorter time horizon (40-50 years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbeg = time.time()\n",
    "\n",
    "new_costs, new_NPV = [0]*len(mismatches), [0]*len(mismatches)\n",
    "new_choices = [0]*len(mismatches)\n",
    "old_costs = [0]*len(mismatches)\n",
    "\n",
    "# dict keys don't have fixed order, so save as a list\n",
    "mismatch_segments = list(mismatches.keys())\n",
    "\n",
    "# subset to only segments we need\n",
    "dfNsub = dfN.loc[(dfN.segments.isin(mismatch_segments))]\n",
    "dfOsub = dfO.loc[(dfO.segments.isin(mismatch_segments))]\n",
    "dfGsub = dfG.loc[(dfG.segments.isin(mismatch_segments))]\n",
    "\n",
    "for seg in mismatch_segments:\n",
    "    s = mismatch_segments.index(seg)\n",
    "\n",
    "    t=1 # needs to be reset each segment\n",
    "    option_costs = []\n",
    "    for var in [\"RetreatCost\",\"ProtectCost\",\"NoAdaptCost\"]:\n",
    "        for lev in levs[var]:\n",
    "            if var != \"NoAdaptCost\":\n",
    "                NPV = dfNsub.loc[(dfNsub.variable==var) & (dfNsub.segments==seg) & \n",
    "                                 (dfNsub.level==lev), \"value\"]*discountfactor\n",
    "            else:\n",
    "                NPV = dfNsub.loc[(dfNsub.variable==var) & (dfNsub.segments==seg),\"value\"]*discountfactor\n",
    "            option_costs.append(np.sum(NPV))\n",
    "    new_NPV[s] = min(option_costs)\n",
    "    new_choices[s] = options[option_costs.index(new_NPV[s])]\n",
    "    # get the new optimal costs in this time step\n",
    "    var = new_choices[s][:7]+\"Cost\"  # RetreatCost, ProtectCost, NoAdaptCost\n",
    "    lev = int(re.findall(r'\\d+', new_choices[s])[0])\n",
    "    if var != \"NoAdaptCost\":\n",
    "        new_costs[s] = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                        (dfNsub.variable==var) & (dfNsub.level==lev), \"value\"])\n",
    "    else:\n",
    "        new_costs[s] = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                        (dfNsub.variable==var), \"value\"])\n",
    "    old_costs[s] = float(dfOsub.loc[(dfOsub.segments==seg) & (dfOsub.time==t), \"OptimalCost\"])\n",
    "\n",
    "    # correct the results dataframes to match the GAMS version's perfect foresight\n",
    "    dfO.loc[(dfO.segments==seg),\"variable\"] = var  # these are assuming fixed mode\n",
    "    dfO.loc[(dfO.segments==seg),\"level\"] = lev\n",
    "    dfO.loc[(dfO.segments==seg) & (dfO.time==t),\"OptimalCost\"] = new_costs[s]\n",
    "    dfN.loc[(dfN.segments==seg) & (dfN.time==t) & (dfN.variable==\"OptimalCost\"), \"value\"] = new_costs[s]\n",
    "    dfC.loc[(dfC.time==t) & (dfC.variable==\"OptimalCost\"), \"value\"] = dfC.loc[(dfC.time==t) & (dfC.variable==\"OptimalCost\"), \"value\"] - \\\n",
    "                                                                      old_costs[s] + new_costs[s]\n",
    "    # In subsequent years, the choice and level stay the same. So, just need to correct things in dfO, dfN, and dfC. \n",
    "    # Retain the other versions of these dataframes from above to compare how the perfect foresight leads to an overestimation of costs.\n",
    "    for t in dfC.time.unique()[1:]:\n",
    "        if var!=\"NoAdaptCost\":\n",
    "            optcost = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                       (dfNsub.variable==var) & (dfNsub.level==lev), \"value\"])\n",
    "        else:\n",
    "            optcost = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & \n",
    "                                       (dfNsub.variable==var), \"value\"])\n",
    "        old_optcost = float(dfNsub.loc[(dfNsub.segments==seg) & (dfNsub.time==t) & (dfNsub.variable==\"OptimalCost\"), \"value\"])\n",
    "        dfN.loc[(dfN.segments==seg) & (dfN.time==t) & (dfN.variable==\"OptimalCost\"), \"value\"] = optcost\n",
    "        dfO.loc[(dfO.segments==seg) & (dfO.time==t), \"OptimalCost\"] = optcost\n",
    "        dfC.loc[(dfC.time==t) & (dfC.variable==\"OptimalCost\"), \"value\"] += optcost - old_optcost\n",
    "        \n",
    "tend = time.time()\n",
    "print((tend-tbeg)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned DataFrames that reflect the perfect foresight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC.to_csv(\"dfC.csv\")\n",
    "dfN.to_csv(\"dfN.csv\")\n",
    "dfO.to_csv(\"dfO.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to process a pair of results DataFrames (need optimal costs/actions one, the total costs one, and the subcosts one) into the form needed to make the bar chart decomposition of costs (below). Assumes `fixed=true`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_costs_df(dfC, dfO, dfN, tmax=False):\n",
    "    # set up\n",
    "    ntime = len(dfO.time.unique())\n",
    "    levs = {\"RetreatCost\" : [1,10,100,1000,10000], \"ProtectCost\" : [10,100,1000,10000], \"NoAdaptCost\" : [0]}\n",
    "    \n",
    "    # figure out which segments pursue which adaptation options, and at what levels of protection\n",
    "    actions = {}\n",
    "    for choice in levs.keys():\n",
    "        for lev in levs[choice]:\n",
    "            if lev > 0:\n",
    "                actions[choice+str(lev)] = list(dfO.loc[(dfO.time==1)&(dfO.variable==choice)&(dfO.level==lev),\"segments\"])\n",
    "            else:\n",
    "                actions[choice+str(lev)] = list(dfO.loc[(dfO.time==1)&(dfO.variable==choice),\"segments\"])\n",
    "    retreat_segs, protect_segs = [], []\n",
    "    for lev in levs[\"RetreatCost\"]:\n",
    "        retreat_segs += actions[\"RetreatCost\"+str(lev)]\n",
    "    for lev in levs[\"ProtectCost\"]:\n",
    "        protect_segs += actions[\"ProtectCost\"+str(lev)]\n",
    "        \n",
    "    # tally up costs associated with each action\n",
    "    retreat_costs_N = [0]*ntime\n",
    "    protect_costs_N = [0]*ntime\n",
    "    inundation_costs_N = [0]*ntime\n",
    "    wetland_costs_N = [0]*ntime\n",
    "    flood_costs_N = [0]*ntime\n",
    "    \n",
    "    for t in range(1,ntime+1):\n",
    "        dfNsub = dfN.loc[(dfN.time==t)] # subset to speed the loop up\n",
    "        # retreat\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            retreat_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"RelocateRetreat\") & (dfNsub.level==lev), \"value\"].sum()\n",
    "        retreat_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable==\"RelocateNoAdapt\"), \"value\"].sum()\n",
    "        # protect\n",
    "        for lev in levs[\"ProtectCost\"]:\n",
    "            pname = \"ProtectCost\"+str(lev)\n",
    "            protect_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"Construct\") & (dfNsub.level==lev), \"value\"].sum()\n",
    "        # inundation (Flood)\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            inundation_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"FloodRetreat\") & (dfNsub.level==lev), \"value\"].sum()\n",
    "        inundation_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable==\"FloodNoAdapt\"), \"value\"].sum()\n",
    "        # wetland\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            wetland_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"WetlandRetreat\"), \"value\"].sum()\n",
    "        for lev in levs[\"ProtectCost\"]:\n",
    "            pname = \"ProtectCost\"+str(lev)\n",
    "            wetland_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.variable==\"WetlandProtect\"), \"value\"].sum()\n",
    "        wetland_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable==\"WetlandNoAdapt\"), \"value\"].sum()\n",
    "        # flooding (Storm)\n",
    "        for lev in levs[\"RetreatCost\"]:\n",
    "            pname = \"RetreatCost\"+str(lev)\n",
    "            flood_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.level==lev) & (dfNsub.variable.isin([\"StormCapitalRetreat\",\"StormPopRetreat\"])), \"value\"].sum()\n",
    "        for lev in levs[\"ProtectCost\"]:\n",
    "            pname = \"ProtectCost\"+str(lev)\n",
    "            flood_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[pname])) & (dfNsub.level==lev) & (dfNsub.variable.isin([\"StormCapitalProtect\",\"StormPopProtect\"])), \"value\"].sum()\n",
    "        flood_costs_N[t-1] += dfNsub.loc[(dfNsub.segments.isin(actions[\"NoAdaptCost0\"])) & (dfNsub.variable.isin([\"StormCapitalNoAdapt\",\"StormPopNoAdapt\"])), \"value\"].sum()\n",
    "\n",
    "    if not tmax:\n",
    "        tmax = ntime\n",
    "        \n",
    "    dfNew = pd.DataFrame()\n",
    "    dfNew[\"time\"] = list(range(1,ntime+1))\n",
    "    dfNew[\"NoAdapt\"] = list(dfC.loc[(dfC.variable==\"NoAdaptCost\"), \"value\"])\n",
    "    dfNew[\"Optimal\"] = list(dfC.loc[(dfC.variable==\"OptimalCost\"), \"value\"])\n",
    "    dfNew[\"FloodNoAdapt\"] = list(dfC.loc[(dfC.variable==\"FloodNoAdapt\"), \"value\"])\n",
    "    dfNew[\"WetlandNoAdapt\"] = list(dfC.loc[(dfC.variable==\"WetlandNoAdapt\"), \"value\"])\n",
    "    dfNew[\"RelocateNoAdapt\"] = list(dfC.loc[(dfC.variable==\"RelocateNoAdapt\"), \"value\"])\n",
    "    dfNew[\"StormCapitalNoAdapt\"] = list(dfC.loc[(dfC.variable==\"StormCapitalNoAdapt\"), \"value\"])\n",
    "    dfNew[\"StormPopNoAdapt\"] = list(dfC.loc[(dfC.variable==\"StormPopNoAdapt\"), \"value\"])\n",
    "    dfNew[\"RetreatOptimal\"] = retreat_costs_N\n",
    "    dfNew[\"ProtectOptimal\"] = protect_costs_N\n",
    "    dfNew[\"InundationOptimal\"] = inundation_costs_N\n",
    "    dfNew[\"WetlandOptimal\"] = wetland_costs_N\n",
    "    dfNew[\"FloodOptimal\"] = flood_costs_N\n",
    "    dfNew = dfNew.loc[(dfNew.time <= tmax)]\n",
    "    \n",
    "    return dfNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline result - matching to GAMS CIAM, both with perfect foresight\n",
    "dfNew0 = process_costs_df(dfC=dfC, dfO=dfO, dfN=dfN, tmax=10)\n",
    "dfNew0[\"year\"] = dfNew0[\"time\"]*10 + 2000\n",
    "\n",
    "# limited foresight result - only difference relative to GAMS CIAM is limited foresigh1\n",
    "dfNew1 = process_costs_df(dfC=dfC1, dfO=dfO1, dfN=dfN1, tmax=10)\n",
    "dfNew1[\"year\"] = dfNew1[\"time\"]*10 + 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to compare the old results (Diaz 2016) to the new ones (this work), with the baseline model configuration. The baseline configuration should match the forcings/inputs for the Diaz 2016 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(dfD, dfN, var, lev=False, times=list(range(1,11)), verbose=True):\n",
    "    varD = var\n",
    "    names = {\"OptimalCost\" : \"OptimalFixedCost\"}#, \"Construct\" : \"ConstructOptimalFixed\"}\n",
    "    if var in names.keys():\n",
    "        varD = names[var]\n",
    "    if lev:\n",
    "        D = [dfD.loc[(dfD.variable==varD) & (dfD.level==lev) & (dfD.time==t), \"value\"].sum() for t in times]\n",
    "        N = list(dfN.loc[(dfN.variable==var) & (dfN.level==lev) & (dfN.time>=times[0]) & (dfN.time<=np.max(times)), \"value\"])\n",
    "    else:\n",
    "        D = [dfD.loc[(dfD.variable==varD) & (dfD.time==t), \"value\"].sum() for t in times]\n",
    "        N = list(dfN.loc[(dfN.variable==var) & (dfN.time>=times[0]) & (dfN.time<=np.max(times)), \"value\"])\n",
    "    if verbose:\n",
    "        print(\"time | Diaz | New\")\n",
    "        for t in range(len(times)):\n",
    "            print(times[t], np.round(D[t],3), np.round(N[t],3))\n",
    "    return [N[t]-D[t] for t in range(len(times))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking NoAdaptCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"NoAdaptCost\", lev=False, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking OptimalCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"OptimalCost\", lev=False, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check RetreatCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"RetreatCost\", lev=10, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check ProtectCost..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"ProtectCost\", lev=10, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Construct costs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = compare(dfG, dfC, var=\"Construct\", lev=100, times=list(range(1,12)), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: total no-adaptation and optimal costs over time - just matching old version (GAMS, Diaz 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 1.8\n",
    "fig,ax = plt.subplots(nrows=2, ncols=1, figsize=(8,10))\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.NoAdapt, width=3, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[0].bar(x=dfNew0.year+sep, height=dfNew0.NoAdapt, width=3, color=\"darkorange\", label=\"This work\")\n",
    "ax[0].grid(); ax[0].set_axisbelow(True)\n",
    "yticks = [0,500,1000,1500,2000]; ax[0].set_yticks(yticks); ax[0].set_yticklabels(yticks, fontsize=12)\n",
    "ax[0].set_xticks(range(2010,2110,10)); ax[0].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[0].set_xlabel(\"Year\", fontsize=12); ax[0].set_ylabel(\"Annual No-Adapt Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ax[0].legend(fontsize=12)\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.Optimal, width=3, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[1].bar(x=dfNew0.year+sep, height=dfNew0.Optimal, width=3, color=\"darkorange\", label=\"This work\")\n",
    "ax[1].grid(); ax[1].set_axisbelow(True)\n",
    "yticks = [0,50,100,150,200,250,300]; ax[1].set_yticks(yticks); ax[1].set_yticklabels(yticks, fontsize=12)\n",
    "ax[1].set_xticks(range(2010,2110,10)); ax[1].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[1].set_xlabel(\"Year\", fontsize=12); ax[1].set_ylabel(\"Annual Least-Cost\\n(billion 2010$US)\", fontsize=12);\n",
    "fig.savefig(\"baseline_comparison_rcp85.pdf\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure: total no-adaptation and optimal costs over time - version of figure with perfect foresight (matching GAMS version) and limited foresight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### total costs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 2.5\n",
    "wid = 2.2\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols=1, figsize=(8,10))\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.NoAdapt, width=wid, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[0].bar(x=dfNew0.year, height=dfNew0.NoAdapt, width=wid, color=\"darkorange\", label=\"This work, perfect foresight\")\n",
    "ax[0].bar(x=dfNew1.year+sep, height=dfNew1.NoAdapt, width=wid, color=\"firebrick\", label=\"This work, limited foresight\")\n",
    "ax[0].grid(); ax[0].set_axisbelow(True); ax[0].set_xlim([2005,2105])\n",
    "yticks = [0,500,1000,1500,2000]; ax[0].set_yticks(yticks); ax[0].set_yticklabels(yticks, fontsize=12)\n",
    "ax[0].set_xticks(range(2010,2110,10)); ax[0].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[0].set_xlabel(\"Year\", fontsize=12); ax[0].set_ylabel(\"Annual No-Adapt Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ax[0].legend(fontsize=12)\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.Optimal, width=wid, color=\"steelblue\", label=\"Diaz (2016)\")\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.Optimal, width=wid, color=\"darkorange\", label=\"This work\")\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.Optimal, width=wid, color=\"firebrick\", label=\"This work, limited foresight\")\n",
    "ax[1].grid(); ax[1].set_axisbelow(True); ax[0].set_xlim([2005,2105])\n",
    "yticks = [0,50,100,150,200,250,300]; ax[1].set_yticks(yticks); ax[1].set_yticklabels(yticks, fontsize=12)\n",
    "ax[1].set_xticks(range(2010,2110,10)); ax[1].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[1].set_xlabel(\"Year\", fontsize=12); ax[1].set_ylabel(\"Annual Least-Cost\\n(billion 2010$US)\", fontsize=12);\n",
    "fig.savefig(\"baseline_comparison_rcp85.pdf\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with cost breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get optimal actions/costs for this work\n",
    "\n",
    "Get which segments adapt which which options and to which levels. Avoid doing any loops over segments, because that will be very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levs = {\"RetreatCost\" : [1,10,100,1000,10000], \"ProtectCost\" : [10,100,1000,10000], \"NoAdaptCost\" : [0]}\n",
    "actions0, actions1 = {}, {}\n",
    "\n",
    "actions0[\"retreat1\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"RetreatCost\")&(dfO.level==1),\"segments\"])\n",
    "actions0[\"retreat10\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"RetreatCost\")&(dfO.level==10),\"segments\"])\n",
    "actions0[\"retreat100\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"RetreatCost\")&(dfO.level==100),\"segments\"])\n",
    "actions0[\"retreat1000\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"RetreatCost\")&(dfO.level==1000),\"segments\"])\n",
    "actions0[\"retreat10000\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"RetreatCost\")&(dfO.level==10000),\"segments\"])\n",
    "actions0[\"protect10\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"ProtectCost\")&(dfO.level==10),\"segments\"])\n",
    "actions0[\"protect100\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"ProtectCost\")&(dfO.level==100),\"segments\"])\n",
    "actions0[\"protect1000\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"ProtectCost\")&(dfO.level==1000),\"segments\"])\n",
    "actions0[\"protect10000\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"ProtectCost\")&(dfO.level==10000),\"segments\"])\n",
    "actions0[\"noadapt\"] = list(dfO.loc[(dfO.time==1)&(dfO.variable==\"NoAdaptCost\"),\"segments\"])\n",
    "\n",
    "actions1[\"retreat1\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"RetreatCost\")&(dfO1.level==1),\"segments\"])\n",
    "actions1[\"retreat10\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"RetreatCost\")&(dfO1.level==10),\"segments\"])\n",
    "actions1[\"retreat100\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"RetreatCost\")&(dfO1.level==100),\"segments\"])\n",
    "actions1[\"retreat1000\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"RetreatCost\")&(dfO1.level==1000),\"segments\"])\n",
    "actions1[\"retreat10000\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"RetreatCost\")&(dfO1.level==10000),\"segments\"])\n",
    "actions1[\"protect10\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"ProtectCost\")&(dfO1.level==10),\"segments\"])\n",
    "actions1[\"protect100\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"ProtectCost\")&(dfO1.level==100),\"segments\"])\n",
    "actions1[\"protect1000\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"ProtectCost\")&(dfO1.level==1000),\"segments\"])\n",
    "actions1[\"protect10000\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"ProtectCost\")&(dfO1.level==10000),\"segments\"])\n",
    "actions1[\"noadapt\"] = list(dfO1.loc[(dfO1.time==1)&(dfO1.variable==\"NoAdaptCost\"),\"segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreat_segs0 = actions0[\"retreat1\"]+actions0[\"retreat10\"]+actions0[\"retreat100\"]+actions0[\"retreat1000\"]+actions0[\"retreat10000\"]\n",
    "protect_segs0 = actions0[\"protect10\"]+actions0[\"protect100\"]+actions0[\"protect1000\"]+actions0[\"protect10000\"]\n",
    "retreat_segs1 = actions1[\"retreat1\"]+actions1[\"retreat10\"]+actions1[\"retreat100\"]+actions1[\"retreat1000\"]+actions1[\"retreat10000\"]\n",
    "protect_segs1 = actions1[\"protect10\"]+actions1[\"protect100\"]+actions1[\"protect1000\"]+actions1[\"protect10000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retreat_segs1) - len(retreat_segs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protect_segs1) - len(protect_segs0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actions1[\"noadapt\"]) - len(actions0[\"noadapt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get optimal actions/costs for Diaz (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_we_want = [\"WetlandOptimalFixed\", \"RelocateOptimalFixed\", \"StormCapitalOptimalFixed\", \n",
    "                   \"StormPopOptimalFixed\", \"ConstructOptimalFixed\", \"FloodOptimalFixed\"]\n",
    "dfGsub = dfG.loc[(dfG.variable.isin(columns_we_want))]\n",
    "flood_G, wetland_G, inundation_G, retreat_G, protect_G = [0]*20, [0]*20, [0]*20, [0]*20, [0]*20\n",
    "for t in range(1,21):\n",
    "    retreat_G[t-1] = dfGsub.loc[(dfGsub.time==t) & (dfGsub.variable==\"RelocateOptimalFixed\"), \"value\"].sum()\n",
    "    protect_G[t-1] = dfGsub.loc[(dfGsub.time==t) & (dfGsub.variable==\"ConstructOptimalFixed\"), \"value\"].sum()\n",
    "    inundation_G[t-1] = dfGsub.loc[(dfGsub.time==t) & (dfGsub.variable==\"FloodOptimalFixed\"), \"value\"].sum()\n",
    "    wetland_G[t-1] = dfGsub.loc[(dfGsub.time==t) & (dfGsub.variable==\"WetlandOptimalFixed\"), \"value\"].sum()\n",
    "    flood_G[t-1] = dfGsub.loc[(dfGsub.time==t) & ((dfGsub.variable==\"StormCapitalOptimalFixed\")|(dfGsub.variable==\"StormPopOptimalFixed\")), \"value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDiaz[\"RetreatOptimal\"] = retreat_G[:10]\n",
    "dfDiaz[\"ProtectOptimal\"] = protect_G[:10]\n",
    "dfDiaz[\"InundationOptimal\"] = inundation_G[:10]\n",
    "dfDiaz[\"WetlandOptimal\"] = wetland_G[:10]\n",
    "dfDiaz[\"FloodOptimal\"] = flood_G[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little funky with how the variables are named, but what Diaz (2016) refers to in Figure 2 as \"flood\" damages is the losses to property and lives from storms (`StormCapital` and `StormPop`), which \"inundation\" is the actual flooded area (`Flood`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 2.8\n",
    "wid = 2.3\n",
    "cost_cols = {\"protect\" : \"gray\", \"retreat\" : \"coral\", \"inundation\" : \"skyblue\", \"wetland\" : \"mediumseagreen\", \"flood\" : \"gold\"}\n",
    "hat = [1*'.', 1*'/', 1*'x']\n",
    "panels = [\"a.\",\"b.\",\"c.\",\"d.\",\"e.\",\"f.\",\"g.\",\"h.\"]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols=1, figsize=(8,11))\n",
    "# PANEL A: NO ADAPTATION COSTS\n",
    "pan = 0\n",
    "# set up for the legend\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=1, width=.5, color=\"white\", edgecolor=\"black\", label=\"Original CIAM\")\n",
    "ax[0].bar(x=dfNew0.year, height=1, width=.5, color=\"white\", hatch=2*hat[2], edgecolor=\"black\", label=\"MimiCIAM, perfect foresight\")\n",
    "ax[0].bar(x=dfNew1.year, height=1, width=.5, color=\"white\", hatch=2*hat[0], edgecolor=\"black\", label=\"MimiCIAM, limited foresight\")\n",
    "# Diaz (2016) results\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=1, width=.5, color=cost_cols[\"protect\"], label=\"protect\")\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.RelocateNoAdapt, width=wid, color=cost_cols[\"retreat\"], label=\"retreat\")\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.FloodNoAdapt, bottom=dfDiaz.RelocateNoAdapt, width=wid, color=cost_cols[\"inundation\"], label=\"inundation\")\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.WetlandNoAdapt, bottom=dfDiaz.RelocateNoAdapt+dfDiaz.FloodNoAdapt, width=wid, color=cost_cols[\"wetland\"], label=\"wetland\")\n",
    "ax[0].bar(x=dfDiaz.time-sep, height=dfDiaz.StormCapitalNoAdapt+dfDiaz.StormPopNoAdapt, bottom=dfDiaz.RelocateNoAdapt+dfDiaz.FloodNoAdapt+dfDiaz.WetlandNoAdapt, width=wid, color=cost_cols[\"flood\"], label=\"flood\")\n",
    "# This work, perfect foresight (match Diaz 2016)\n",
    "ax[0].bar(x=dfNew0.year, height=dfNew0.RelocateNoAdapt, width=wid, color=cost_cols[\"retreat\"], hatch=hat[2])\n",
    "ax[0].bar(x=dfNew0.year, height=dfNew0.FloodNoAdapt,bottom=dfNew0.RelocateNoAdapt,\n",
    "          width=wid, color=cost_cols[\"inundation\"], hatch=hat[2])\n",
    "ax[0].bar(x=dfNew0.year, height=dfNew0.WetlandNoAdapt, bottom=dfNew0.FloodNoAdapt+dfNew0.RelocateNoAdapt,\n",
    "          width=wid, color=cost_cols[\"wetland\"], hatch=hat[2])\n",
    "ax[0].bar(x=dfNew0.year, height=dfNew0.StormCapitalNoAdapt+dfNew0.StormPopNoAdapt, bottom=dfNew0.RelocateNoAdapt+dfNew0.FloodNoAdapt+dfNew0.WetlandNoAdapt,\n",
    "          width=wid, color=cost_cols[\"flood\"], hatch=hat[2])\n",
    "# This work, limited foresight\n",
    "ax[0].bar(x=dfNew1.year+sep, height=dfNew1.RelocateNoAdapt, width=wid, color=cost_cols[\"retreat\"], hatch=hat[0])\n",
    "ax[0].bar(x=dfNew1.year+sep, height=dfNew1.FloodNoAdapt,bottom=dfNew1.RelocateNoAdapt,\n",
    "          width=wid, color=cost_cols[\"inundation\"], hatch=hat[0])\n",
    "ax[0].bar(x=dfNew1.year+sep, height=dfNew1.WetlandNoAdapt, bottom=dfNew1.FloodNoAdapt+dfNew1.RelocateNoAdapt,\n",
    "          width=wid, color=cost_cols[\"wetland\"], hatch=hat[0])\n",
    "ax[0].bar(x=dfNew1.year+sep, height=dfNew1.StormCapitalNoAdapt+dfNew1.StormPopNoAdapt, bottom=dfNew1.RelocateNoAdapt+dfNew1.FloodNoAdapt+dfNew1.WetlandNoAdapt,\n",
    "          width=wid, color=cost_cols[\"flood\"], hatch=hat[0])\n",
    "# other plot configuration options\n",
    "ax[0].grid(); ax[0].set_axisbelow(True); ax[0].set_xlim([2005,2105])\n",
    "yticks = [0,500,1000,1500,2000]; ax[0].set_yticks(yticks); ax[0].set_yticklabels(yticks, fontsize=12)\n",
    "ax[0].set_xticks(range(2010,2110,10)); ax[0].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[0].set_xlabel(\"Year\", fontsize=12); ax[0].set_ylabel(\"Annual No-Adapt Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ax[0].legend(fontsize=12)\n",
    "ylims = ax[0].get_ylim(); top = ylims[1]*1.02; ax[0].text(2005,top, panels[pan], fontsize=12);\n",
    "\n",
    "# PANEL B: OPTIMAL COSTS\n",
    "pan += 1\n",
    "# Diaz (2016) results\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.ProtectOptimal, width=wid, color=cost_cols[\"protect\"])\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.RetreatOptimal, bottom=dfDiaz.ProtectOptimal, width=wid, color=cost_cols[\"retreat\"])\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.InundationOptimal, bottom=dfDiaz.ProtectOptimal+dfDiaz.RetreatOptimal, width=wid, color=cost_cols[\"inundation\"])\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.WetlandOptimal, bottom=dfDiaz.ProtectOptimal+dfDiaz.RetreatOptimal+dfDiaz.InundationOptimal, width=wid, color=cost_cols[\"wetland\"])\n",
    "ax[1].bar(x=dfDiaz.time-sep, height=dfDiaz.FloodOptimal, bottom=dfDiaz.ProtectOptimal+dfDiaz.RetreatOptimal+dfDiaz.InundationOptimal+dfDiaz.WetlandOptimal, width=wid, color=cost_cols[\"flood\"])\n",
    "# This work, perfect foresight (match Diaz 2016)\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.ProtectOptimal, width=wid, color=cost_cols[\"protect\"], hatch=hat[2])\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.RetreatOptimal, bottom=dfNew0.ProtectOptimal, width=wid, color=cost_cols[\"retreat\"], hatch=hat[2])\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.InundationOptimal,bottom=dfNew0.ProtectOptimal+dfNew0.RetreatOptimal, width=wid, color=cost_cols[\"inundation\"], hatch=hat[2])\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.WetlandOptimal, bottom=dfNew0.ProtectOptimal+dfNew0.RetreatOptimal+dfNew0.InundationOptimal, width=wid, color=cost_cols[\"wetland\"], hatch=hat[2])\n",
    "ax[1].bar(x=dfNew0.year, height=dfNew0.FloodOptimal, bottom=dfNew0.ProtectOptimal+dfNew0.RetreatOptimal+dfNew0.InundationOptimal+dfNew0.WetlandOptimal, width=wid, color=cost_cols[\"flood\"], hatch=hat[2])\n",
    "# This work, limited foresight\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.ProtectOptimal, width=wid, color=cost_cols[\"protect\"], hatch=hat[0])\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.RetreatOptimal, bottom=dfNew1.ProtectOptimal, width=wid, color=cost_cols[\"retreat\"], hatch=hat[0])\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.InundationOptimal,bottom=dfNew1.ProtectOptimal+dfNew1.RetreatOptimal, width=wid, color=cost_cols[\"inundation\"], hatch=hat[0])\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.WetlandOptimal, bottom=dfNew1.ProtectOptimal+dfNew1.RetreatOptimal+dfNew1.InundationOptimal, width=wid, color=cost_cols[\"wetland\"], hatch=hat[0])\n",
    "ax[1].bar(x=dfNew1.year+sep, height=dfNew1.FloodOptimal, bottom=dfNew1.ProtectOptimal+dfNew1.RetreatOptimal+dfNew1.InundationOptimal+dfNew1.WetlandOptimal, width=wid, color=cost_cols[\"flood\"], hatch=hat[0])\n",
    "\n",
    "# other plot configuration options\n",
    "ax[1].grid(); ax[1].set_axisbelow(True); ax[1].set_xlim([2005,2105])\n",
    "yticks = [0,50,100,150,200,250,300]; ax[1].set_yticks(yticks); ax[1].set_yticklabels(yticks, fontsize=12)\n",
    "ax[1].set_xticks(range(2010,2110,10)); ax[1].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[1].set_xlabel(\"Year\", fontsize=12); ax[1].set_ylabel(\"Annual Least-Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ylims = ax[1].get_ylim(); top = ylims[1]*1.02; ax[1].text(2005,top, panels[pan], fontsize=12);\n",
    "fig.savefig(\"baseline_comparison_rcp85.pdf\", bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline\n",
    "\n",
    "construct fix, limited foresight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfO = pd.read_csv(dir_julia + \"/ctrl_seg_85p50ssp0fixed_optimal.csv\")\n",
    "dfN = pd.read_csv(dir_julia + \"/ctrl_seg_85p50ssp0fixed.csv\")\n",
    "dfC = pd.read_csv(dir_julia + \"/ctrl_global_85p50ssp0fixed.csv\")\n",
    "df_ctrl = process_costs_df(dfC=dfC, dfO=dfO, dfN=dfN, tmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline+updated SLR\n",
    "\n",
    "construct fix, limited foresight, BRICK RCP8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfO = pd.read_csv(dir_julia + \"/ctrl+BRICKLSL85_seg_85p50ssp0fixed_optimal.csv\")\n",
    "dfN = pd.read_csv(dir_julia + \"/ctrl+BRICKLSL85_seg_85p50ssp0fixed.csv\")\n",
    "dfC = pd.read_csv(dir_julia + \"/ctrl+BRICKLSL85_global_85p50ssp0fixed.csv\")\n",
    "df_BRICK85 = process_costs_df(dfC=dfC, dfO=dfO, dfN=dfN, tmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline+updated GDP/population via SSP5 & Jones and O'Neill (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfO = pd.read_csv(dir_julia + \"/ctrl+SSP5+popJones_seg_85p50ssp5fixed_optimal.csv\")\n",
    "dfN = pd.read_csv(dir_julia + \"/ctrl+SSP5+popJones_seg_85p50ssp5fixed.csv\")\n",
    "dfC = pd.read_csv(dir_julia + \"/ctrl+SSP5+popJones_global_85p50ssp5fixed.csv\")\n",
    "df_SSP5 = process_costs_df(dfC=dfC, dfO=dfO, dfN=dfN, tmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline+updated SLR+updated GPD/population via SSP5 & Jones and O'Neill (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfO = pd.read_csv(dir_julia + \"/ctrl+SSP5+popJones+BRICKLSL85_seg_85p50ssp5fixed_optimal.csv\")\n",
    "dfN = pd.read_csv(dir_julia + \"/ctrl+SSP5+popJones+BRICKLSL85_seg_85p50ssp5fixed.csv\")\n",
    "dfC = pd.read_csv(dir_julia + \"/ctrl+SSP5+popJones+BRICKLSL85_global_85p50ssp5fixed.csv\")\n",
    "df_SSP5_BRICK85 = process_costs_df(dfC=dfC, dfO=dfO, dfN=dfN, tmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctrl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctrl.RelocateNoAdapt[idx_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = 2\n",
    "wid = 3.1\n",
    "cost_cols = {\"protect\" : \"gray\", \"retreat\" : \"coral\", \"inundation\" : \"skyblue\", \"wetland\" : \"mediumseagreen\", \"flood\" : \"gold\"}\n",
    "times_plot = list(range(2010,2110,10))\n",
    "idx_plot = [1,3,5,7,9]\n",
    "times_plot = np.array([times_plot[k] for k in idx_plot])\n",
    "hat = [1*'.', 1*'/', 1*'x']\n",
    "panels = [\"a.\",\"b.\",\"c.\",\"d.\",\"e.\",\"f.\",\"g.\",\"h.\"]\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, ncols=1, figsize=(8,11))\n",
    "# PANEL A: NO ADAPTATION COSTS\n",
    "pan = 0\n",
    "# set up for the legend\n",
    "ax[0].bar(x=times_plot[0], height=1, width=.5, color=\"white\", edgecolor=\"black\", label=\"MimiCIAM baseline\")\n",
    "ax[0].bar(x=times_plot[0], height=1, width=.5, color=\"white\", hatch=2*hat[0], edgecolor=\"black\", label=\"MimiCIAM, SSP5\")\n",
    "ax[0].bar(x=times_plot[0], height=1, width=.5, color=\"white\", hatch=2*hat[1], edgecolor=\"black\", label=\"MimiCIAM, BRICK RCP8.5\")\n",
    "ax[0].bar(x=times_plot[0], height=1, width=.5, color=\"white\", hatch=2*hat[2], edgecolor=\"black\", label=\"MimiCIAM, SSP5, BRICK RCP8.5\")\n",
    "# ctrl\n",
    "ax[0].bar(x=times_plot-3*sep, height=1, width=.5, color=cost_cols[\"protect\"], label=\"protect\")\n",
    "ax[0].bar(x=times_plot-3*sep, height=df_ctrl.RelocateNoAdapt[idx_plot], width=wid, color=cost_cols[\"retreat\"], label=\"retreat\")\n",
    "ax[0].bar(x=times_plot-3*sep, height=df_ctrl.FloodNoAdapt[idx_plot], bottom=np.array(df_ctrl.RelocateNoAdapt[idx_plot]), width=wid, color=cost_cols[\"inundation\"], label=\"inundation\")\n",
    "ax[0].bar(x=times_plot-3*sep, height=df_ctrl.WetlandNoAdapt[idx_plot], bottom=np.array(df_ctrl.RelocateNoAdapt[idx_plot]+df_ctrl.FloodNoAdapt[idx_plot]), width=wid, color=cost_cols[\"wetland\"], label=\"wetland\")\n",
    "ax[0].bar(x=times_plot-3*sep, height=df_ctrl.StormCapitalNoAdapt[idx_plot]+df_ctrl.StormPopNoAdapt[idx_plot], bottom=np.array(df_ctrl.RelocateNoAdapt[idx_plot]+df_ctrl.FloodNoAdapt[idx_plot]+df_ctrl.WetlandNoAdapt[idx_plot]), width=wid, color=cost_cols[\"flood\"], label=\"flood\")\n",
    "# SSP5 pop & GDP\n",
    "ax[0].bar(x=times_plot-sep, height=1, width=.5, color=cost_cols[\"protect\"], hatch=hat[0])\n",
    "ax[0].bar(x=times_plot-sep, height=df_SSP5.RelocateNoAdapt[idx_plot], width=wid, color=cost_cols[\"retreat\"], hatch=hat[0])\n",
    "ax[0].bar(x=times_plot-sep, height=df_SSP5.FloodNoAdapt[idx_plot], bottom=np.array(df_SSP5.RelocateNoAdapt[idx_plot]), width=wid, color=cost_cols[\"inundation\"], hatch=hat[0])\n",
    "ax[0].bar(x=times_plot-sep, height=df_SSP5.WetlandNoAdapt[idx_plot], bottom=np.array(df_SSP5.RelocateNoAdapt[idx_plot]+df_SSP5.FloodNoAdapt[idx_plot]), width=wid, color=cost_cols[\"wetland\"], hatch=hat[0])\n",
    "ax[0].bar(x=times_plot-sep, height=df_SSP5.StormCapitalNoAdapt[idx_plot]+df_SSP5.StormPopNoAdapt[idx_plot], bottom=np.array(df_SSP5.RelocateNoAdapt[idx_plot]+df_SSP5.FloodNoAdapt[idx_plot]+df_SSP5.WetlandNoAdapt[idx_plot]), width=wid, color=cost_cols[\"flood\"], hatch=hat[0])\n",
    "# BRICK SLR RCP8.5\n",
    "ax[0].bar(x=times_plot+sep, height=1, width=.5, color=cost_cols[\"protect\"], hatch=hat[1])\n",
    "ax[0].bar(x=times_plot+sep, height=df_BRICK85.RelocateNoAdapt[idx_plot], width=wid, color=cost_cols[\"retreat\"], hatch=hat[1])\n",
    "ax[0].bar(x=times_plot+sep, height=df_BRICK85.FloodNoAdapt[idx_plot], bottom=np.array(df_BRICK85.RelocateNoAdapt[idx_plot]), width=wid, color=cost_cols[\"inundation\"], hatch=hat[1])\n",
    "ax[0].bar(x=times_plot+sep, height=df_BRICK85.WetlandNoAdapt[idx_plot], bottom=np.array(df_BRICK85.RelocateNoAdapt[idx_plot]+df_BRICK85.FloodNoAdapt[idx_plot]), width=wid, color=cost_cols[\"wetland\"], hatch=hat[1])\n",
    "ax[0].bar(x=times_plot+sep, height=df_BRICK85.StormCapitalNoAdapt[idx_plot]+df_BRICK85.StormPopNoAdapt[idx_plot], bottom=np.array(df_BRICK85.RelocateNoAdapt[idx_plot]+df_BRICK85.FloodNoAdapt[idx_plot]+df_BRICK85.WetlandNoAdapt[idx_plot]), width=wid, color=cost_cols[\"flood\"], hatch=hat[1])\n",
    "# BRICK SLR RCP8.5 & SSP5 pop/GDP\n",
    "ax[0].bar(x=times_plot+3*sep, height=1, width=.5, color=cost_cols[\"protect\"], hatch=hat[2])\n",
    "ax[0].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.RelocateNoAdapt[idx_plot], width=wid, color=cost_cols[\"retreat\"], hatch=hat[2])\n",
    "ax[0].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.FloodNoAdapt[idx_plot], bottom=np.array(df_SSP5_BRICK85.RelocateNoAdapt[idx_plot]), width=wid, color=cost_cols[\"inundation\"], hatch=hat[2])\n",
    "ax[0].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.WetlandNoAdapt[idx_plot], bottom=np.array(df_SSP5_BRICK85.RelocateNoAdapt[idx_plot]+df_SSP5_BRICK85.FloodNoAdapt[idx_plot]), width=wid, color=cost_cols[\"wetland\"], hatch=hat[2])\n",
    "ax[0].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.StormCapitalNoAdapt[idx_plot]+df_SSP5_BRICK85.StormPopNoAdapt[idx_plot], bottom=np.array(df_SSP5_BRICK85.RelocateNoAdapt[idx_plot]+df_SSP5_BRICK85.FloodNoAdapt[idx_plot]+df_SSP5_BRICK85.WetlandNoAdapt[idx_plot]), width=wid, color=cost_cols[\"flood\"], hatch=hat[2])\n",
    "# other plot configuration options\n",
    "ax[0].grid(); ax[0].set_axisbelow(True); ax[0].set_xlim([2010,2110]); ax[0].set_ylim([0,5500])\n",
    "yticks = list(range(0,5500,500)); ax[0].set_yticks(yticks); ax[0].set_yticklabels(yticks, fontsize=12)\n",
    "ax[0].set_xticks(range(2010,2110,10)); ax[0].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[0].set_xlabel(\"Year\", fontsize=12); ax[0].set_ylabel(\"Annual No-Adapt Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ax[0].legend(fontsize=12)\n",
    "ylims = ax[0].get_ylim(); top = ylims[1]*1.02; ax[0].text(2010,top, panels[pan], fontsize=12);\n",
    "\n",
    "# PANEL B: OPTIMAL COSTS\n",
    "pan += 1\n",
    "# ctrl\n",
    "ax[1].bar(x=times_plot-3*sep, height=df_ctrl.ProtectOptimal[idx_plot], width=wid, color=cost_cols[\"protect\"], label=\"protect\")\n",
    "ax[1].bar(x=times_plot-3*sep, height=df_ctrl.RetreatOptimal[idx_plot], bottom=np.array(df_ctrl.ProtectOptimal[idx_plot]), width=wid, color=cost_cols[\"retreat\"], label=\"retreat\")\n",
    "ax[1].bar(x=times_plot-3*sep, height=df_ctrl.InundationOptimal[idx_plot], bottom=np.array(df_ctrl.ProtectOptimal[idx_plot]+df_ctrl.RetreatOptimal[idx_plot]), width=wid, color=cost_cols[\"inundation\"], label=\"inundation\")\n",
    "ax[1].bar(x=times_plot-3*sep, height=df_ctrl.WetlandOptimal[idx_plot], bottom=np.array(df_ctrl.ProtectOptimal[idx_plot]+df_ctrl.RetreatOptimal[idx_plot]+df_ctrl.InundationOptimal[idx_plot]), width=wid, color=cost_cols[\"wetland\"], label=\"wetland\")\n",
    "ax[1].bar(x=times_plot-3*sep, height=df_ctrl.FloodOptimal[idx_plot], bottom=np.array(df_ctrl.ProtectOptimal[idx_plot]+df_ctrl.RetreatOptimal[idx_plot]+df_ctrl.InundationOptimal[idx_plot]+df_ctrl.WetlandOptimal[idx_plot]), width=wid, color=cost_cols[\"flood\"], label=\"flood\")\n",
    "# SSP5 pop & .25\n",
    "ax[1].bar(x=times_plot-sep, height=df_SSP5.ProtectOptimal[idx_plot], width=wid, color=cost_cols[\"protect\"], hatch=hat[0])\n",
    "ax[1].bar(x=times_plot-sep, height=df_SSP5.RetreatOptimal[idx_plot], bottom=np.array(df_SSP5.ProtectOptimal[idx_plot]), width=wid, color=cost_cols[\"retreat\"], hatch=hat[0])\n",
    "ax[1].bar(x=times_plot-sep, height=df_SSP5.InundationOptimal[idx_plot], bottom=np.array(df_SSP5.ProtectOptimal[idx_plot]+df_SSP5.RetreatOptimal[idx_plot]), width=wid, color=cost_cols[\"inundation\"], hatch=hat[0])\n",
    "ax[1].bar(x=times_plot-sep, height=df_SSP5.WetlandOptimal[idx_plot], bottom=np.array(df_SSP5.ProtectOptimal[idx_plot]+df_SSP5.RetreatOptimal[idx_plot]+df_SSP5.InundationOptimal[idx_plot]), width=wid, color=cost_cols[\"wetland\"], hatch=hat[0])\n",
    "ax[1].bar(x=times_plot-sep, height=df_SSP5.FloodOptimal[idx_plot], bottom=np.array(df_SSP5.ProtectOptimal[idx_plot]+df_SSP5.RetreatOptimal[idx_plot]+df_SSP5.InundationOptimal[idx_plot]+df_SSP5.WetlandOptimal[idx_plot]), width=wid, color=cost_cols[\"flood\"], hatch=hat[0])\n",
    "# BRICK SLR RCP8.5\n",
    "ax[1].bar(x=times_plot+sep, height=df_BRICK85.ProtectOptimal[idx_plot], width=wid, color=cost_cols[\"protect\"], hatch=hat[1])\n",
    "ax[1].bar(x=times_plot+sep, height=df_BRICK85.RetreatOptimal[idx_plot], bottom=np.array(df_BRICK85.ProtectOptimal[idx_plot]), width=wid, color=cost_cols[\"retreat\"], hatch=hat[1])\n",
    "ax[1].bar(x=times_plot+sep, height=df_BRICK85.InundationOptimal[idx_plot], bottom=np.array(df_BRICK85.ProtectOptimal[idx_plot]+df_BRICK85.RetreatOptimal[idx_plot]), width=wid, color=cost_cols[\"inundation\"], hatch=hat[1])\n",
    "ax[1].bar(x=times_plot+sep, height=df_BRICK85.WetlandOptimal[idx_plot], bottom=np.array(df_BRICK85.ProtectOptimal[idx_plot]+df_BRICK85.RetreatOptimal[idx_plot]+df_BRICK85.InundationOptimal[idx_plot]), width=wid, color=cost_cols[\"wetland\"], hatch=hat[1])\n",
    "ax[1].bar(x=times_plot+sep, height=df_BRICK85.FloodOptimal[idx_plot], bottom=np.array(df_BRICK85.ProtectOptimal[idx_plot]+df_BRICK85.RetreatOptimal[idx_plot]+df_BRICK85.InundationOptimal[idx_plot]+df_BRICK85.WetlandOptimal[idx_plot]), width=wid, color=cost_cols[\"flood\"], hatch=hat[1])\n",
    "# BRICK SLR RCP8.5 & SSP5 pop/GDP\n",
    "ax[1].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.ProtectOptimal[idx_plot], width=wid, color=cost_cols[\"protect\"], hatch=hat[2])\n",
    "ax[1].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.RetreatOptimal[idx_plot], bottom=np.array(df_SSP5_BRICK85.ProtectOptimal[idx_plot]), width=wid, color=cost_cols[\"retreat\"], hatch=hat[2])\n",
    "ax[1].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.InundationOptimal[idx_plot], bottom=np.array(df_SSP5_BRICK85.ProtectOptimal[idx_plot]+df_SSP5_BRICK85.RetreatOptimal[idx_plot]), width=wid, color=cost_cols[\"inundation\"], hatch=hat[2])\n",
    "ax[1].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.WetlandOptimal[idx_plot], bottom=np.array(df_SSP5_BRICK85.ProtectOptimal[idx_plot]+df_SSP5_BRICK85.RetreatOptimal[idx_plot]+df_SSP5_BRICK85.InundationOptimal[idx_plot]), width=wid, color=cost_cols[\"wetland\"], hatch=hat[2])\n",
    "ax[1].bar(x=times_plot+3*sep, height=df_SSP5_BRICK85.FloodOptimal[idx_plot], bottom=np.array(df_SSP5_BRICK85.ProtectOptimal[idx_plot]+df_SSP5_BRICK85.RetreatOptimal[idx_plot]+df_SSP5_BRICK85.InundationOptimal[idx_plot]+df_SSP5_BRICK85.WetlandOptimal[idx_plot]), width=wid, color=cost_cols[\"flood\"], hatch=hat[2]) \n",
    "# other plot configuration options\n",
    "ax[1].grid(); ax[1].set_axisbelow(True); ax[1].set_xlim([2010,2110])\n",
    "yticks = list(range(0,800,100)); ax[1].set_yticks(yticks); ax[1].set_yticklabels(yticks, fontsize=12)\n",
    "ax[1].set_xticks(range(2010,2110,10)); ax[1].set_xticklabels([\"\",2020,\"\",2040,\"\",2060,\"\",2080,\"\",2100], fontsize=12)\n",
    "ax[1].set_xlabel(\"Year\", fontsize=12); ax[1].set_ylabel(\"Annual Least-Cost\\n(billion 2010$US)\", fontsize=12)\n",
    "ylims = ax[1].get_ylim(); top = ylims[1]*1.02; ax[1].text(2010,top, panels[pan], fontsize=12);\n",
    "fig.savefig(\"updates_comparison_rcp85.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
